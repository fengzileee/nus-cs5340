{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ff0155",
   "metadata": {},
   "source": [
    "# Tests and sanity checks of HMM implementations\n",
    "\n",
    "For basic functionality tests of our HMM implementations, we use a simple Markov chain setup based on a coin-flipping task.\n",
    "\n",
    "Consider a coin-flipping task where there are 2 states: 1) we are holding an unbiased coin and 2) we are holding a biased coin. Between coin flips, there is a probability p that we switch coins. This gives a Markov chain with a 2x2 transition matrix. The unbiased coin state has index 0 and the biased coin state has index 1.\n",
    "    \n",
    "There are two possible observations/emissions from each coin flip. We can either observe: 1) heads or 2) tails. The probability of observing heads/tails from the unbiased coin state is 0.5, and the probability from the biased coin state is q/1-q, for some probability q. The heads emission has index 0 and the tails emission has index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addb039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49166a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition_matrix(p):\n",
    "    return np.array([[p, 1-p], [1-p, p]])\n",
    "\n",
    "def make_emission_matrix(q):\n",
    "    return np.array([[0.5, 0.5], [q, 1-q]])\n",
    "\n",
    "def draw_sequence(A, B, prior, T):\n",
    "    num_states, num_obs = B.shape\n",
    "    state = np.random.choice(num_states, 1, p=prior).item()\n",
    "    emissions = [np.random.choice(num_obs, 1, p=B[state].flatten()).item()]\n",
    "    for t in range(1, T):\n",
    "        state = np.random.choice(num_states, 1, p=A[state].flatten()).item()\n",
    "        emissions.append(np.random.choice(num_obs, 1, p=B[state].flatten()).item())\n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd8802",
   "metadata": {},
   "source": [
    "## Multinomial HMM based on 1st order Markov chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb1e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_motion_prediction.predictor import HMMMultinomialFirstOrder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205abb0",
   "metadata": {},
   "source": [
    "We test the forward/backward algorithms used for estimating the likelihood of a given sequence of emissions/observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d901f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "q = 0.5\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0424ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625 0.06250000000000003\n"
     ]
    }
   ],
   "source": [
    "hmm1 = HMMMultinomialFirstOrder(2, 2, verbose=True)\n",
    "hmm1.initialise_parameters(transition_matrix, prior, emission_matrix)\n",
    "test_seq1 = np.array([0, 0, 1, 0])\n",
    "prob1 = hmm1.get_sequence_likelihood_backward(test_seq1)\n",
    "prob2 = hmm1.get_sequence_likelihood(test_seq1)\n",
    "\n",
    "print(prob1, prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c954140",
   "metadata": {},
   "source": [
    "We test the decoding algorithms used to estimate the most likely sequence of hidden states that produced the sequence of emissions/observations in our data. The decoding algorithm implemented is the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ade997",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "q = 0.999 # Use 0.999 instead of 1, because I have yet to handle the case of np.log(0) in log-sum-exp function.\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaf85a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1]\n",
      "0.06237506250000003\n"
     ]
    }
   ],
   "source": [
    "hmm2 = HMMMultinomialFirstOrder(2, 2, verbose=True)\n",
    "hmm2.initialise_parameters(transition_matrix, prior, emission_matrix)\n",
    "test_seq2 = np.array([1, 0, 0])\n",
    "path, prob = hmm2.decode(test_seq2)\n",
    "print(path)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b462d",
   "metadata": {},
   "source": [
    "Test the estimation of HMM model parameters from data. This uses the specialised form of the EM algorithm, the Baum-Welch algorithm. The algorithm can be prone to local minima, and may not converge well when all the parameters to be estimated are not well-initialised. You can test its robustness to initialisation but selectively initialising some of the parameters using the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73edc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "q = 0.999 # Use 0.999 instead of 1, because I have yet to handle the case of np.log(0) in log-sum-exp function.\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45899fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 1 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 1]]\n",
      "Estimating HMM model parameters...\n",
      "Iter 1, log-likelihood loss: -7.024722607974975, delta: inf\n",
      "Iter 2, log-likelihood loss: -5.664936102659883, delta: 1.3597865053150917\n",
      "Iter 3, log-likelihood loss: -5.66131013548803, delta: 0.0036259671718532616\n",
      "Iter 4, log-likelihood loss: -5.658889304612112, delta: 0.0024208308759181563\n",
      "Iter 5, log-likelihood loss: -5.657255492287608, delta: 0.0016338123245036584\n",
      "Iter 6, log-likelihood loss: -5.656145098736711, delta: 0.0011103935508973706\n",
      "Iter 7, log-likelihood loss: -5.655387159901618, delta: 0.0007579388350924532\n",
      "Iter 8, log-likelihood loss: -5.65486849272569, delta: 0.0005186671759283001\n",
      "Iter 9, log-likelihood loss: -5.654513089781826, delta: 0.0003554029438639361\n",
      "Iter 10, log-likelihood loss: -5.654269421616268, delta: 0.00024366816555776438\n",
      "Iter 11, log-likelihood loss: -5.654102342983989, delta: 0.00016707863227960473\n",
      "Iter 12, log-likelihood loss: -5.653987797731999, delta: 0.00011454525198928422\n",
      "Iter 13, log-likelihood loss: -5.653909288519687, delta: 7.85092123125608e-05\n",
      "Iter 14, log-likelihood loss: -5.653855492412965, delta: 5.379610672218149e-05\n",
      "Iter 15, log-likelihood loss: -5.65381863681706, delta: 3.685559590493881e-05\n",
      "Iter 16, log-likelihood loss: -5.653793387648064, delta: 2.5249168995600257e-05\n",
      "Iter 17, log-likelihood loss: -5.653776086052482, delta: 1.730159558199773e-05\n",
      "Iter 18, log-likelihood loss: -5.6537642237406756, delta: 1.1862311806609682e-05\n",
      "Iter 19, log-likelihood loss: -5.653756082226236, delta: 8.141514439508057e-06\n",
      "Transition\n",
      "[[0.31238621 0.68761379]\n",
      " [0.17969314 0.82030686]]\n",
      "Emission\n",
      "[[0.75423715 0.24576285]\n",
      " [0.74447049 0.25552951]]\n",
      "Prior\n",
      "[0.83414374 0.16585626]\n",
      "Estimating HMM model parameters...\n",
      "Iter 1, log-likelihood loss: -5.653750484830988, delta: inf\n",
      "Iter 2, log-likelihood loss: -5.653746626305527, delta: 3.858525460920248e-06\n",
      "Loaded and Trained Transition\n",
      "[[0.31225263 0.68774737]\n",
      " [0.1797245  0.8202755 ]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([draw_sequence(transition_matrix, emission_matrix, prior, 10) for i in range(500)])\n",
    "print(data)\n",
    "\n",
    "# Don't give the correct values for any of the parameters. Use random initialisation.\n",
    "hmm3 = HMMMultinomialFirstOrder(2, 2, verbose=True)\n",
    "hmm3.estimate_parameters(data)\n",
    "\n",
    "print(\"Transition\")\n",
    "print(np.exp(hmm3._log_A))\n",
    "print(\"Emission\")\n",
    "print(np.exp(hmm3._log_B))\n",
    "print(\"Prior\")\n",
    "print(np.exp(hmm3._log_phi))\n",
    "\n",
    "hmm3.save_to_file(\"./hmm_sanity_check_param.pickle\")\n",
    "\n",
    "hmm3_load = HMMMultinomialFirstOrder(2, 2, verbose=True)\n",
    "hmm3_load.load_from_file(\"./hmm_sanity_check_param.pickle\")\n",
    "hmm3_load.estimate_parameters(data)\n",
    "print(\"Loaded and Trained Transition\")\n",
    "print(np.exp(hmm3_load._log_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb2d9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 1 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 1]]\n",
      "Estimating HMM model parameters...\n",
      "Iter 1, log-likelihood loss: -7.3160232371448695, delta: inf\n",
      "Iter 2, log-likelihood loss: -5.653891440391395, delta: 1.6621317967534743\n",
      "Iter 3, log-likelihood loss: -5.653879230677302, delta: 1.220971409310323e-05\n",
      "Iter 4, log-likelihood loss: -5.653867394295645, delta: 1.1836381657026607e-05\n",
      "Iter 5, log-likelihood loss: -5.653855915128039, delta: 1.1479167605799034e-05\n",
      "Iter 6, log-likelihood loss: -5.653844777992499, delta: 1.113713554001805e-05\n",
      "Iter 7, log-likelihood loss: -5.653833968573029, delta: 1.0809419470625414e-05\n",
      "Iter 8, log-likelihood loss: -5.653823473355083, delta: 1.0495217945383217e-05\n",
      "Iter 9, log-likelihood loss: -5.65381327956661, delta: 1.0193788472889764e-05\n",
      "Iter 10, log-likelihood loss: -5.653803375123801, delta: 9.9044428090167e-06\n",
      "Transition\n",
      "[[0.45704322 0.54295678]\n",
      " [0.45960241 0.54039759]]\n",
      "Emission\n",
      "[[0.68387724 0.31612276]\n",
      " [0.80043714 0.19956286]]\n",
      "Prior\n",
      "[0.44145927 0.55854073]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([draw_sequence(transition_matrix, emission_matrix, prior, 10) for i in range(500)])\n",
    "print(data)\n",
    "\n",
    "# Initialise the transition and prior models using correct values, and try to estimate the emission probabilities.\n",
    "hmm3 = HMMMultinomialFirstOrder(2, 2, verbose=True)\n",
    "hmm3._initialise_transition_model(transition_matrix)\n",
    "hmm3._initialise_prior_distribution(prior)\n",
    "hmm3.estimate_parameters(data)\n",
    "\n",
    "print(\"Transition\")\n",
    "print(np.exp(hmm3._log_A))\n",
    "print(\"Emission\")\n",
    "print(np.exp(hmm3._log_B))\n",
    "print(\"Prior\")\n",
    "print(np.exp(hmm3._log_phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15000bbf",
   "metadata": {},
   "source": [
    "## Multinomial HMM based on 2nd order Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d54ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_motion_prediction.predictor import HMMMultinomialSecondOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04d251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition_matrix(p):\n",
    "    return np.array([[[p, 1-p], [1-p, p]], [[p, 1-p], [1-p, p]]])\n",
    "\n",
    "def make_emission_matrix(q):\n",
    "    return np.array([[0.5, 0.5], [q, 1-q]])\n",
    "\n",
    "def draw_sequence(A, B, prior, T):\n",
    "    num_states, num_obs = B.shape\n",
    "    state = np.random.choice(num_states, 1, p=prior).item()\n",
    "    emissions = [np.random.choice(num_obs, 1, p=B[state].flatten()).item()]\n",
    "    last_state = np.random.choice(num_states, 1, p=prior).item() \n",
    "    for t in range(1, T):\n",
    "        state = np.random.choice(num_states, 1, p=A[last_state][state].flatten()).item()\n",
    "        emissions.append(np.random.choice(num_obs, 1, p=B[state].flatten()).item())\n",
    "        last_state = state \n",
    "    return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c6d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25000000000000006 0.25000000000000006\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "q = 0.5\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])\n",
    "\n",
    "hmm1 = HMMMultinomialSecondOrder(2, 2, verbose=True)\n",
    "hmm1.initialise_parameters(transition_matrix, prior, emission_matrix)\n",
    "test_seq1 = np.array([0, 1, 1])\n",
    "\n",
    "prob1 = hmm1.get_sequence_likelihood_backward(test_seq1)\n",
    "prob2 = hmm1.get_sequence_likelihood(test_seq1)\n",
    "\n",
    "print(prob1, prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4db054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0]\n",
      "0.12487499999999999\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "q = 0.999\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])\n",
    "\n",
    "hmm1.initialise_parameters(transition_matrix, prior, emission_matrix)\n",
    "test_seq2 = np.array([1, 0, 0, 1])\n",
    "path, prob = hmm1.decode(test_seq2)\n",
    "print(path)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3993b034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 1 0 1]\n",
      " [0 1 1 ... 1 0 1]\n",
      " [1 0 1 ... 1 0 1]]\n",
      "Estimating HMM model parameters...\n",
      "Iter 1, log-likelihood loss: -7.6726156109352495, delta: inf\n",
      "Iter 2, log-likelihood loss: -7.615431786708141, delta: 0.057183824227108104\n",
      "Iter 3, log-likelihood loss: -7.620815414847124, delta: 0.005383628138982743\n",
      "Iter 4, log-likelihood loss: -7.6192365151072705, delta: 0.0015788997398535898\n",
      "Iter 5, log-likelihood loss: -7.612326174715188, delta: 0.0069103403920829365\n",
      "Iter 6, log-likelihood loss: -7.5985124039371845, delta: 0.013813770778003054\n",
      "Iter 7, log-likelihood loss: -7.581638692056695, delta: 0.01687371188048914\n",
      "Iter 8, log-likelihood loss: -7.56698867217573, delta: 0.014650019880965814\n",
      "Iter 9, log-likelihood loss: -7.558699536572356, delta: 0.00828913560337341\n",
      "Iter 10, log-likelihood loss: -7.558593810143422, delta: 0.00010572642893436068\n",
      "Iter 11, log-likelihood loss: -7.565966338528428, delta: 0.007372528385006127\n",
      "Iter 12, log-likelihood loss: -7.578184559947095, delta: 0.012218221418667241\n",
      "Iter 13, log-likelihood loss: -7.5918749175531985, delta: 0.013690357606103376\n",
      "Iter 14, log-likelihood loss: -7.60416066496233, delta: 0.012285747409131353\n",
      "Iter 15, log-likelihood loss: -7.613399314825807, delta: 0.009238649863476667\n",
      "Iter 16, log-likelihood loss: -7.619245091920836, delta: 0.005845777095029092\n",
      "Iter 17, log-likelihood loss: -7.622255566007676, delta: 0.003010474086840631\n",
      "Iter 18, log-likelihood loss: -7.623372167116026, delta: 0.0011166011083494354\n",
      "Iter 19, log-likelihood loss: -7.623494665822086, delta: 0.0001224987060606253\n",
      "Iter 20, log-likelihood loss: -7.623231357515536, delta: 0.0002633083065504138\n",
      "Iter 21, log-likelihood loss: -7.622826478923282, delta: 0.00040487859225368794\n",
      "Iter 22, log-likelihood loss: -7.622230034209707, delta: 0.0005964447135751172\n",
      "Iter 23, log-likelihood loss: -7.621252724390221, delta: 0.000977309819486294\n",
      "Iter 24, log-likelihood loss: -7.619735178063778, delta: 0.0015175463264425204\n",
      "Iter 25, log-likelihood loss: -7.617667254760338, delta: 0.002067923303440189\n",
      "Iter 26, log-likelihood loss: -7.6152229152330015, delta: 0.002444339527336581\n",
      "Iter 27, log-likelihood loss: -7.6127150029434, delta: 0.002507912289601677\n",
      "Iter 28, log-likelihood loss: -7.610502753748143, delta: 0.0022122491952565326\n",
      "Iter 29, log-likelihood loss: -7.608893283062555, delta: 0.0016094706855884766\n",
      "Iter 30, log-likelihood loss: -7.608069910152561, delta: 0.0008233729099940135\n",
      "Iter 31, log-likelihood loss: -7.608063806264279, delta: 6.103888281927539e-06\n",
      "Transition\n",
      "[[[0.5001843  0.4998157 ]\n",
      "  [0.49437887 0.49394322]]\n",
      "\n",
      " [[0.50540084 0.50641506]\n",
      "  [0.49948234 0.50051766]]]\n",
      "Emission\n",
      "[[0.43811679 0.56188321]\n",
      " [0.58023233 0.41976767]]\n",
      "Prior\n",
      "[0.46819444 0.54153211]\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "q = 0.5\n",
    "transition_matrix = make_transition_matrix(p)\n",
    "emission_matrix = make_emission_matrix(q)\n",
    "prior = np.array([0.5, 0.5])\n",
    "    \n",
    "data = np.array([draw_sequence(transition_matrix, emission_matrix, prior, 12) for i in range(500)])\n",
    "print(data)\n",
    "\n",
    "hmm1 = HMMMultinomialSecondOrder(2, 2, verbose=True)\n",
    "hmm1._initialise_transition_model(transition_matrix)\n",
    "hmm1._initialise_prior_distribution(prior)\n",
    "hmm1.estimate_parameters(data)\n",
    "\n",
    "print(\"Transition\")\n",
    "print(np.exp(hmm1._log_A))\n",
    "print(\"Emission\")\n",
    "print(np.exp(hmm1._log_B))\n",
    "print(\"Prior\")\n",
    "print(np.exp(hmm1._log_phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eca6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
